"""
M√≥dulo de transcripci√≥n de audio usando Whisper (faster-whisper).
Carga el modelo en memoria la primera vez y lo reutiliza.

Modelos disponibles (nombre ‚Üí tama√±o en disco):
  tiny    ‚Üí  ~39 MB  (m√°s r√°pido, menos preciso)
  base    ‚Üí  ~74 MB  ‚Üê por defecto
  small   ‚Üí ~244 MB
  medium  ‚Üí ~769 MB
  large-v3‚Üí ~1.5 GB

Requiere ffmpeg en el PATH del sistema.
  Windows: https://ffmpeg.org/download.html  (o: winget install ffmpeg)
"""

import os
import tempfile
import logging

log = logging.getLogger(__name__)

# ‚îÄ‚îÄ Configuraci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

WHISPER_MODEL_SIZE = os.getenv("WHISPER_MODEL", "base")   # cambia aqu√≠ o con variable de entorno
WHISPER_DEVICE     = "cpu"          # "cuda" si tienes GPU NVIDIA con CUDA
WHISPER_COMPUTE    = "int8"         # "float16" para GPU, "int8" para CPU

# ‚îÄ‚îÄ Estado global (singleton del modelo) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

_model = None


def _get_model():
    """Carga el modelo Whisper la primera vez (lazy loading)."""
    global _model
    if _model is None:
        try:
            from faster_whisper import WhisperModel
        except ImportError:
            raise RuntimeError(
                "faster-whisper no est√° instalado. "
                "Ejecuta: pip install faster-whisper"
            )
        log.info(f"‚è≥  Cargando modelo Whisper '{WHISPER_MODEL_SIZE}' en {WHISPER_DEVICE}...")
        _model = WhisperModel(
            WHISPER_MODEL_SIZE,
            device=WHISPER_DEVICE,
            compute_type=WHISPER_COMPUTE,
        )
        log.info("‚úÖ  Modelo Whisper cargado.")
    return _model


# ‚îÄ‚îÄ Funci√≥n principal ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def transcribe_audio(audio_bytes: bytes, filename: str = "audio.wav") -> str:
    """
    Transcribe un audio a texto.

    Par√°metros:
        audio_bytes: contenido binario del fichero de audio
        filename:    nombre original (se usa la extensi√≥n para el fichero temporal)

    Devuelve:
        Texto transcrito como string. Vac√≠o si no se detect√≥ habla.

    Formatos soportados (con ffmpeg instalado):
        mp3, mp4, m4a, ogg, wav, webm, flac, ...
    """
    model = _get_model()

    # Guardar en fichero temporal con la extensi√≥n correcta
    ext = os.path.splitext(filename)[1] or ".wav"
    with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as tmp:
        tmp.write(audio_bytes)
        tmp_path = tmp.name

    try:
        segments, info = model.transcribe(
            tmp_path,
            beam_size=5,
            language=None,          # detecci√≥n autom√°tica de idioma
            vad_filter=True,        # filtra silencios
        )
        text = " ".join(seg.text.strip() for seg in segments).strip()
        detected_lang = info.language
        log.info(f"üéôÔ∏è  Transcripci√≥n completa. Idioma detectado: {detected_lang}. Texto: '{text}'")
        return text
    finally:
        os.unlink(tmp_path)


def is_whisper_available() -> bool:
    """Comprueba si faster-whisper est√° instalado."""
    try:
        import faster_whisper  # noqa: F401
        return True
    except ImportError:
        return False
